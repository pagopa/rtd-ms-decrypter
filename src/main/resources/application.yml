logging:
  level:
    root: INFO

decrypt:
  resources:
    base:
      path: src/test/resources
  private:
    key:
      path: ${CSV_TRANSACTION_PRIVATE_KEY_PATH:${decrypt.resources.base.path}/certs/private_base64.key} # just for tests
      password: ${CSV_TRANSACTION_PRIVATE_KEY_PASS:privatekeypass}
  api:
    baseurl: https://${CSV_TRANSACTION_DECRYPT_HOST:internal.it}
  blobclient:
    basepath: storage
    apikey: ${INTERNAL_SERVICES_API_KEY:myapikey}
    targetContainer:
      rtd: rtd-transactions-decrypted
      ade: ade-transactions-decrypted
  splitter:
    threshold: ${SPLITTER_LINE_THRESHOLD:250000}
  enableChunkUpload: ${ENABLE_CHUNK_UPLOAD:false}
  skipChecksum: ${SKIP_CHECKSUM:false}
---
spring:
  config:
    activate:
      on-profile: test
  cloud:
    stream:
      bindings:
        blobStorageConsumer-in-0: # name must match [handler name]-in-0
          destination: rtd-platform-events
          group: rtd-decrypter-consumer-group
          content-type: application/json
          binder: kafka
      kafka:
        binder:
          auto-create-topics: false
          consumerProperties:
            key:
              deserializer: org.apache.kafka.common.serialization.StringDeserializer
            value:
              deserializer: org.apache.kafka.common.serialization.StringDeserializer
---
spring:
  config:
    activate:
      on-profile: default
  cloud:
    stream:
      bindings:
        blobStorageConsumer-in-0: # name must match [handler name]-in-0
          destination: rtd-platform-events
          group: rtd-decrypter-consumer-group
          content-type: application/json
          binder: kafka
      kafka:
        binder:
          auto-create-topics: false
          brokers: ${KAFKA_BROKER}
          configuration:
            max.poll.interval.ms: ${CONSUMER_TIMEOUT_MS:600000} # default to 10 min
            max.poll.records: 1
            sasl:
              jaas:
                config: ${KAFKA_SASL_JAAS_CONFIG_CONSUMER_BLOB_STORAGE_EVENTS}
              mechanism: PLAIN
            security:
              protocol: SASL_SSL
          consumerProperties:
            key:
              deserializer: org.apache.kafka.common.serialization.StringDeserializer
            value:
              deserializer: org.apache.kafka.common.serialization.StringDeserializer
            socket:
              connection:
                setup:
                  timeout:
                    max:
                      ms: 200000
                    ms: 100000
            request:
              timeout:
                ms: 60000
            connections:
              max:
                idle:
                  ms: 180000
            max:
              partition:
                fetch:
                  bytes: 10485760
            session:
              timeout:
                ms: 10000
            metadata:
              max:
                age:
                  ms: 180000
            # partition:
            #   assignment:
            #     strategy: org.apache.kafka.clients.consumer.RangeAssignor
